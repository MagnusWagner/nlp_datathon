{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "north-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastai --upgrade\n",
    "# !pip install transformers --upgrade\n",
    "# !pip uninstall splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "curious-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.text.all import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "from transformers import RobertaTokenizer, RobertaTokenizerFast\n",
    "from splitters import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genuine-cornell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm excited about your programs and use Windows 7 on a notebook (which is a bit cumbersome because it's too small) and an iMac, which is much more comfortable because of the size. Are your programs Apple compatible? ...or are there any problems or limitations? I would appreciate a quick reply, as I am eager to use your programs.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My Super Bill administrator does not work on Windows 7 Where can I get an abgrade version ? or do I have to buy the program again ?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Sir or Madam, on 31.10.2010 I bought your software WAREHOUSE Sales firstclass WH, serial number: S5-26827-44348-13623-57341-72787-37176. Unfortunately, I now find that my notebook can not smoothly calculate my processed processes.    Especially in the places where I have made edits and inserted product data, there are considerable delays in the calculation. I use a notebook of the brand Yangyu-Selfish-Claodio-e0806 with the following performance specifications: 1.Processor: Intel (R) Core (TM) 5 Duo CPU T543 @ 3.3 GHz 3.3GHz3 GByte    2.RAM: 4.0 GB 3. graphics card: NVIDIA Road Gefor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Before burning, the following problem occurs. Where can I adjust my burner, or do I need a new burner. But can not really be? My burner is an integrated one in the laptop. Laptop HP Compaq 2850s burner/drive GWWF corp. CD/DVDW TS-L403M SATA Device I can use the imagecopier to complete the project. Thank you very much for the answer.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So I have recently purchased Specs Manager 9. Now my detailsheet is almost finished -24 sheets/150 MB- only a few more data are missing and then I could finally release it... But now I have a problem which I can't solve by myself: Since a few days I get always the error message \"Not enough memory\" I get at the moment not even my project completely about the program called!!! In the display via the program some data are gone and except for 5-6 sheets all others are gone too...;o( Only via the \"sheets and layers group view\" you can see that the sheets are still there at all. Even the \"Help\"...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                                                                                        I'm excited about your programs and use Windows 7 on a notebook (which is a bit cumbersome because it's too small) and an iMac, which is much more comfortable because of the size. Are your programs Apple compatible? ...or are there any problems or limitations? I would appreciate a quick reply, as I am eager to use your programs.          \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                               My Super Bill administrator does not work on Windows 7 Where can I get an abgrade version ? or do I have to buy the program again ?          \n",
       "2   Dear Sir or Madam, on 31.10.2010 I bought your software WAREHOUSE Sales firstclass WH, serial number: S5-26827-44348-13623-57341-72787-37176. Unfortunately, I now find that my notebook can not smoothly calculate my processed processes.    Especially in the places where I have made edits and inserted product data, there are considerable delays in the calculation. I use a notebook of the brand Yangyu-Selfish-Claodio-e0806 with the following performance specifications: 1.Processor: Intel (R) Core (TM) 5 Duo CPU T543 @ 3.3 GHz 3.3GHz3 GByte    2.RAM: 4.0 GB 3. graphics card: NVIDIA Road Gefor...   \n",
       "3                                                                                                                                                                                                                                                                    Before burning, the following problem occurs. Where can I adjust my burner, or do I need a new burner. But can not really be? My burner is an integrated one in the laptop. Laptop HP Compaq 2850s burner/drive GWWF corp. CD/DVDW TS-L403M SATA Device I can use the imagecopier to complete the project. Thank you very much for the answer.          \n",
       "4   So I have recently purchased Specs Manager 9. Now my detailsheet is almost finished -24 sheets/150 MB- only a few more data are missing and then I could finally release it... But now I have a problem which I can't solve by myself: Since a few days I get always the error message \"Not enough memory\" I get at the moment not even my project completely about the program called!!! In the display via the program some data are gone and except for 5-6 sheets all others are gone too...;o( Only via the \"sheets and layers group view\" you can see that the sheets are still there at all. Even the \"Help\"...   \n",
       "\n",
       "   label  \n",
       "0      4  \n",
       "1      4  \n",
       "2      1  \n",
       "3      2  \n",
       "4      5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"data/train_en.csv\")\n",
    "\n",
    "\n",
    "df=df.drop([\"Column1\"],axis=1)\n",
    "df=df.rename({\"Narrative\":\"text\",\"Abteilung\":\"label\"},axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informed-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastHugsTokenizer():\n",
    "    \"\"\"    \n",
    "        transformer_tokenizer : takes the tokenizer that has been loaded from the tokenizer class\n",
    "        model_name : model type set by the user\n",
    "        max_seq_len : override default sequence length, typically 512 for bert-like models.\n",
    "                           `transformer_tokenizer.max_len_single_sentence` and `transformer_tokenizer.max_len_sentences_pair` \n",
    "                           both account for the need to add additional special tokens, i.e. for RoBERTa-base \n",
    "                           max_len_single_sentence==510, leaving space for the 2 additional special tokens \n",
    "                           to be added for the model's default 512 positional embeddings\n",
    "        pair : whether a single sentence (sequence) or pair of sentences are used\n",
    "        \n",
    "        NOTES:\n",
    "            - `init` will have to be modified to enable sequence lengths larger than the tokenizer default\n",
    "            - need to add case when pretrained==False\n",
    "            - Pretrained==True will cut the sequence at the max length\n",
    "            - Good functions in `tokenization_utils.py`\n",
    "            - tokenizer.encode_plus or tokenizer.batch_encode_plus are great, but don't play nice with fastai multiprocessiing\n",
    "            - https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus\n",
    "            - encoded_dict=tokenizer.encode_plus(text=o, return_tensors=\"pt\", max_length=tokenizer.max_len, pad_to_max_length=True)\n",
    "        Returns:\n",
    "            - Tokenized text, up to the max sequence length set by the user or the tokenzier default\n",
    "    \"\"\"\n",
    "    def __init__(self, transformer_tokenizer=None, model_name='roberta', max_seq_len=None, \n",
    "                 pretrained=True, pair=False, **kwargs): \n",
    "        self.model_name, self.tok, self.max_seq_len=model_name, transformer_tokenizer, max_seq_len\n",
    "        if pretrained:\n",
    "            if self.max_seq_len:\n",
    "                if pair: assert self.max_seq_len<=self.tok.max_len_sentences_pair, 'WARNING: max_seq_len needs to be less than or equal to transformer_tokenizer.max_len_sentences_pair'\n",
    "                else: assert self.max_seq_len<=self.tok.max_len_single_sentence, 'WARNING: max_seq_len needs to be less than or equal to transformer_tokenizer.max_len_single_sentence'\n",
    "            else:\n",
    "                if pair: self.max_seq_len=ifnone(max_seq_len, self.tok.max_len_sentences_pair) \n",
    "                else: self.max_seq_len=ifnone(max_seq_len, self.tok.max_len_single_sentence)\n",
    "\n",
    "    def do_tokenize(self, o:str):\n",
    "        \"\"\"Returns tokenized text, adds prefix space if needed, limits the maximum sequence length\"\"\"\n",
    "        if 'roberta' in model_name: tokens=self.tok.tokenize(o)[:self.max_seq_len-2]\n",
    "        # instead of: if 'roberta' in model_name: tokens=self.tok.tokenize(o, add_prefix_space=True)[:self.max_seq_len-2]\n",
    "        else: tokens = self.tok.tokenize(o)[:self.max_seq_len-2]\n",
    "        return tokens\n",
    "    def __call__(self, items): \n",
    "        for o in items: yield self.do_tokenize(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bigger-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastHugsModel(nn.Module):\n",
    "    'Inspired by https://www.kaggle.com/melissarajaram/roberta-fastai-huggingface-transformers/data'\n",
    "    def __init__(self, transformer_cls, tokenizer, config_dict, n_class, pretrained=True):\n",
    "        super(FastHugsModel, self).__init__()\n",
    "        self.tok, self.config, self.config._num_labels = tokenizer, config_dict, n_class\n",
    "        # load model\n",
    "        if pretrained: self.transformer = transformer_cls.from_pretrained(model_name, config=self.config)\n",
    "        else: self.transformer = transformer_cls.from_config(config=self.config)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        attention_mask = (input_ids!=self.tok.pad_token_id).type(input_ids.type())\n",
    "        logits = self.transformer(input_ids, attention_mask = attention_mask)[0] \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "improving-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base' \n",
    "model_class = AutoModelForSequenceClassification\n",
    "config_dict = AutoConfig.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "logical-thailand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer_vocab=tokenizer.get_vocab() \n",
    "tokenizer_vocab_ls = [k for k, v in sorted(tokenizer_vocab.items(), key=lambda item: item[1])] #wichtig für fastai\n",
    "len(tokenizer_vocab_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "falling-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter_nm = model_name.split('-')[0] + '_cls_splitter'\n",
    "model_splitter = splitters[splitter_nm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "express-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 400\n",
    "sentence_pair=False\n",
    "\n",
    "fasthugstok = FastHugsTokenizer(transformer_tokenizer=tokenizer, model_name=model_name, max_seq_len=max_seq_len, \n",
    "                       sentence_pair=sentence_pair)\n",
    "# instead of: fasthugstok = partial(FastHugsTokenizer, transformer_tokenizer=tokenizer, model_name=model_name, max_seq_len=max_seq_len, sentence_pair=sentence_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "level-password",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method from_df in module fastai.text.core:\n",
      "\n",
      "from_df(text_cols, tok=None, rules=None, sep=' ', n_workers=12, mark_fields=None, tok_text_col='text', **kwargs) method of fastcore.transform._TfmMeta instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Tokenizer.from_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hungry-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai_tokenizer = Tokenizer.from_df(text_cols='text',tok=fasthugstok,n_workers=0,rules=[],tok_text_col='text')\n",
    "#instead of: fastai_tokenizer = Tokenizer.from_df(text_cols='text', res_col_name='text', tok_func=fasthugstok, rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "athletic-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialClsTokens(Transform):\n",
    "    \"Add special token_ids to the numericalized tokens for Sequence Classification\"\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tok=tokenizer\n",
    "    def encodes(self, o):\n",
    "        return(TensorText(self.tok.build_inputs_with_special_tokens(list(o))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "micro-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=[\"If you want the real version of this over blown American clown act, watch William Wylers' 1944 version - the true story of the 'Memphis Belle'. It's amazing what Hollywood will do to distort history and mock its' veterans, all for a buck. Well it must be the American way! Younger viewers will be beguiled by the nonsense, however older viewers with some sense of history will recognize this movie for what it is worth. Don't waste your time! However, if you don't want the truth, then put your mind in neutral and watch this movie.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "brave-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "fht=FastHugsTokenizer(transformer_tokenizer=tokenizer, model_name='roberta', max_seq_len=max_seq_len, \n",
    "                 pretrained=True, pair=False)\n",
    "tokenized_text = next(fht(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "outside-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Numericalize working the same as HuggingFace\n",
    "test_eq(Numericalize(vocab=tokenizer_vocab_ls)(tokenized_text),\n",
    "        TensorText(tokenizer.convert_tokens_to_ids(tokenized_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "latter-moderator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_special length: 118, with_special length: 120\n"
     ]
    }
   ],
   "source": [
    "# Check that additional tokens are being added\n",
    "pre_special=Numericalize(vocab=tokenizer_vocab_ls)(tokenized_text)\n",
    "with_special=SpecialClsTokens(tokenizer)(pre_special)\n",
    "print(f'pre_special length: {len(pre_special)}, with_special length: {len(with_special)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "electrical-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones(df.shape[0], np.bool)\n",
    "trainSplit = np.array(random.sample(range(df.shape[0]),round(0.8*df.shape[0])))\n",
    "mask[trainSplit] = 0\n",
    "validSplit=np.arange(df.shape[0])[mask]\n",
    "df_train=df.iloc[trainSplit,:]\n",
    "df_valid=df.iloc[validSplit,:]\n",
    "all_texts = np.concatenate([df_train.values, df_valid.values])\n",
    "splits = [trainSplit,validSplit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "liquid-payday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "C:\\Users\\Magnus\\miniconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "x_tfms = [attrgetter(\"text\"), fastai_tokenizer, Numericalize(vocab=tokenizer_vocab_ls), SpecialClsTokens(tokenizer)]\n",
    "dsets = Datasets(df,splits=splits, tfms=[x_tfms, [attrgetter(\"label\"), Categorize()]], dl_type=SortedDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dimensional-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transformer_padding(tokenizer=None, max_seq_len=None, sentence_pair=False): \n",
    "    if tokenizer.padding_side == 'right': pad_first=False\n",
    "    else: pad_first=True\n",
    "    max_seq_len = ifnone(max_seq_len, tokenizer.model_max_length)\n",
    "    #instead of: max_seq_len = ifnone(max_seq_len, tokenizer.max_len)\n",
    "    return partial(pad_input_chunk, pad_first=pad_first, pad_idx=tokenizer.pad_token_id, seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "pointed-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "padding=transformer_padding(tokenizer, max_seq_len)\n",
    "dls = dsets.dataloaders(bs=bs, before_batch=[padding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "textile-imaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; ĠAdd endum Ġto Ġd . Ġalready Ġclosed Ġticket # : Ġ16 33 44 30 22 24 22 17 : ĠHello ĠMr . ĠK rem pler , Ġ Ġ Ġ Ġfirst Ġof Ġall ĠI Ġwish Ġyou Ġhappy Ġholidays Ġto Ġhave Ġhad Ġand Ġall Ġthe Ġbest Ġand Ġmainly Ġhealth Ġfor Ġthe Ġnew Ġyear Ġ! Ġ Ġ Ġ ĠUnfortunately , ĠI Ġhave</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; ĠWhen Ġstarting Ġthe Ġsoftware ĠI Ġget Ġthe Ġerror Ġmessage : ĠWAR EH OU SE ĠSales Ġfirst class ĠNeo Ġdoes Ġnot Ġwork Ġanymore ... ĠThen ĠI Ġcan Ġonly Ġclose Ġthe Ġsoftware Ġvia Ġprogram Ġclose . ĠIn Ġthe Ġbackground Ġyou Ġcan Ġsee Ġ\" Program Ġinterface Ġis Ġbeing Ġset Ġup ...\" Ġbut Ġunfortunately Ġit Ġdoes Ġnot Ġgo Ġany Ġfurther . ĠThe Ġproblem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;s&gt; Ġ1 st Ġletter Ġdated Ġapprox . Ġ7 ĠOctober ĠDear ĠSir Ġor ĠMad am , ĠYesterday ĠI Ġwanted Ġto Ġconvert Ġa Ġprocess Ġwith Ġmy ĠCR Ġsettlements Ġfor Ġthe Ġfirst Ġtime . ĠBut Ġunfortunately Ġ( I Ġtried Ġ4 Ġtimes ) Ġthe ĠPC Ġsaved Ġonly Ġa Ġ50 ĠKB Ġversion , Ġalthough Ġthe Ġcard Ġcontained Ġ30 Ġmeg abytes Ġand Ġthe Ġdata Ġcould Ġalso</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=3, trunc_at=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hispanic-fourth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "opt_func = partial(Adam, decouple_wd=True)\n",
    "loss = LabelSmoothingCrossEntropy()\n",
    "\n",
    "fasthugs_model = FastHugsModel(transformer_cls=model_class, tokenizer=tokenizer, \n",
    "                               config_dict=config_dict, n_class=dls.c, pretrained=True)\n",
    "\n",
    "learn = Learner(dls, fasthugs_model, opt_func=opt_func, splitter=model_splitter, \n",
    "                loss_func=loss, metrics=[accuracy]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "humanitarian-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "healthy-greeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/120 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-35d7aa25ab99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuggestions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\fastai\\callback\\schedule.py\u001b[0m in \u001b[0;36mlr_find\u001b[1;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggestions)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[0mn_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[0mcb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLRFinder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstop_div\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_logging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshow_plot\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_lr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msuggestions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\fastai\\data\\load.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__idxs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_idxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# called in context of main process (not workers/subprocesses)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_loaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-israel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-sapphire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-latter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "continuing-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "durable-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = 'gpt2'\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights)\n",
    "model = GPT2LMHeadModel.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "apart-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = np.concatenate([df_train[xsplit].values, df_train[ysplit].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "signal-bearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='600' class='' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [600/600 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]\n",
    "\n",
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        return x if isinstance(x, Tensor) else tokenize(x)\n",
    "        \n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))\n",
    "    \n",
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "infrared-patch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear Sir or Madam, I have been a user of \"sales firstclass 20 Ultimate\" for some time. When using the program's every time there are errors in the additional functions of \"Auto Sort SD\".The error logs I usually also sent. This is of course VERY annoying when working with the program and not very productive!!!!. One function (Getright) is so buggy that not even an output (X) is installed! Once the function is called - it does not go away. One can then only shut down the computer and restart it!!! The project is then of course gone to the last save point - VERY annoying!!!! What can you offer me - so that the program works in the future and I have more pleasure than FRUST when using it.... Finally, the software came me proud 150? and your advertising for this software and its performance is quite rosy</td>\n",
       "      <td>Sir or Madam, I have been a user of \"sales firstclass 20 Ultimate\" for some time. When using the program's every time there are errors in the additional functions of \"Auto Sort SD\".The error logs I usually also sent. This is of course VERY annoying when working with the program and not very productive!!!!. One function (Getright) is so buggy that not even an output (X) is installed! Once the function is called - it does not go away. One can then only shut down the computer and restart it!!! The project is then of course gone to the last save point - VERY annoying!!!! What can you offer me - so that the program works in the future and I have more pleasure than FRUST when using it.... Finally, the software came me proud 150? and your advertising for this software and its performance is quite rosy designed....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is not possible for me to burn even when using other default templates.        The data sheet I created months ago can no longer be loaded into the program with Super Specs Manager8. The message \"not enough memory\" appears. All unnecessary programs have been closed. The problem remains. My specification sheet consists of 3 categories of 150 files and is 55.5 MB in size.        I am trying to install Sales firstclass WH on my computer. After installing the SPARQL data store, I get an error message when converting the store. I can continue to install but the data store is missing. Firewall and virus protection are disabled. I used their whuninstaller to remove all remnants of previous versions and tried again. Problem remains        Dear Warehouse Team!</td>\n",
       "      <td>is not possible for me to burn even when using other default templates.        The data sheet I created months ago can no longer be loaded into the program with Super Specs Manager8. The message \"not enough memory\" appears. All unnecessary programs have been closed. The problem remains. My specification sheet consists of 3 categories of 150 files and is 55.5 MB in size.        I am trying to install Sales firstclass WH on my computer. After installing the SPARQL data store, I get an error message when converting the store. I can continue to install but the data store is missing. Firewall and virus protection are disabled. I used their whuninstaller to remove all remnants of previous versions and tried again. Problem remains        Dear Warehouse Team!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs,sl = 4,256\n",
    "splits = [range_of(df_train[xsplit]), list(range(len(df_train[xsplit]), len(all_texts)))]\n",
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)\n",
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "tamil-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "funny-month",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [4.447630405426025,85.42428588867188]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "permanent-charter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.025118863582611083, lr_steep=0.2089296132326126)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "underlying-alignment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.422462</td>\n",
       "      <td>3.825102</td>\n",
       "      <td>45.837479</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "disturbed-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I need help with my computer system. I do not know\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "abroad-arctic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "exempt-benjamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "preds = learn.model.generate(inp, max_length=40, num_beams=5, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "terminal-ranking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I need help with my computer system. I do not know what to do.                        '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-reducing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
